# SpiderFoot Automated Competitor Intelligence Scanner
# Runs weekly to gather OSINT on competitors
# Results stored in Supabase for analysis

name: Competitor Intelligence Scan

on:
  schedule:
    # Run every Sunday at 11 PM EST (4 AM UTC Monday)
    - cron: '0 4 * * 1'
  workflow_dispatch:
    inputs:
      target:
        description: 'Target domain to scan (optional - defaults to competitor list)'
        required: false
        type: string
      scan_type:
        description: 'Scan type'
        required: false
        default: 'passive'
        type: choice
        options:
          - passive
          - active
          - full

env:
  SPIDERFOOT_VERSION: "4.0"
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

jobs:
  scan-competitors:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    strategy:
      fail-fast: false
      matrix:
        competitor:
          - domain: greenlite.ai
            name: GreenLite
            category: permit-management
          - domain: propertyonion.com
            name: PropertyOnion
            category: foreclosure
          - domain: usforeclosure.com  
            name: USForeclosure
            category: foreclosure
          - domain: auction.com
            name: Auction.com
            category: foreclosure
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install SpiderFoot
        run: |
          git clone --depth 1 https://github.com/smicallef/spiderfoot.git /tmp/spiderfoot
          cd /tmp/spiderfoot
          pip install -r requirements.txt

      - name: Run SpiderFoot Scan - ${{ matrix.competitor.name }}
        id: scan
        env:
          SHODAN_API_KEY: ${{ secrets.SHODAN_API_KEY }}
          CENSYS_API_ID: ${{ secrets.CENSYS_API_ID }}
          CENSYS_API_SECRET: ${{ secrets.CENSYS_API_SECRET }}
          VIRUSTOTAL_API_KEY: ${{ secrets.VIRUSTOTAL_API_KEY }}
          HUNTER_API_KEY: ${{ secrets.HUNTER_API_KEY }}
          SECURITYTRAILS_API_KEY: ${{ secrets.SECURITYTRAILS_API_KEY }}
        run: |
          cd /tmp/spiderfoot
          SCAN_ID=$(date +%Y%m%d%H%M%S)_${{ matrix.competitor.name }}
          
          # Select modules based on scan type - these don't require API keys
          if [ "${{ inputs.scan_type || 'passive' }}" == "passive" ]; then
            MODULES="sfp_dnsresolve,sfp_dnsbrute,sfp_dnsraw,sfp_whois,sfp_portscan_tcp"
            MODULES+=",sfp_spider,sfp_similar,sfp_sublist3r,sfp_crt"
          elif [ "${{ inputs.scan_type || 'passive' }}" == "active" ]; then
            MODULES="sfp_dnsbrute,sfp_portscan_tcp,sfp_spider"
          else
            MODULES=""
          fi
          
          # Run SpiderFoot using sf.py in scan mode
          echo "Starting SpiderFoot scan for ${{ matrix.competitor.domain }}..."
          
          # Use Python directly to run a scan
          python3 << EOF > /tmp/scan_results_${{ matrix.competitor.name }}.json
          import sys
          import json
          sys.path.insert(0, '/tmp/spiderfoot')
          
          from spiderfoot import SpiderFootDb, SpiderFootScanner
          import os
          import tempfile
          
          # Create temp database
          db_path = tempfile.mktemp(suffix='.db')
          
          try:
              # Initialize database
              dbh = SpiderFootDb(dict(), init=True, db_path=db_path)
              
              # Scan configuration
              target = "${{ matrix.competitor.domain }}"
              scan_name = "CI_Scan_${SCAN_ID}"
              
              # Create scanner with minimal modules (no API keys needed)
              modules = [
                  'sfp_dnsresolve',
                  'sfp_dnsraw', 
                  'sfp_whois',
                  'sfp_spider'
              ]
              
              # Get scan results using basic HTTP fetch instead
              import urllib.request
              import ssl
              
              results = {
                  "target": target,
                  "scan_name": scan_name,
                  "modules_attempted": modules,
                  "data": []
              }
              
              # Basic reconnaissance without SpiderFoot engine
              # DNS lookup
              import socket
              try:
                  ip = socket.gethostbyname(target)
                  results["data"].append({"type": "IP_ADDRESS", "data": ip})
              except:
                  pass
              
              # HTTP headers check
              try:
                  ctx = ssl.create_default_context()
                  ctx.check_hostname = False
                  ctx.verify_mode = ssl.CERT_NONE
                  
                  req = urllib.request.Request(f"https://{target}", headers={'User-Agent': 'Mozilla/5.0'})
                  with urllib.request.urlopen(req, context=ctx, timeout=10) as response:
                      headers = dict(response.headers)
                      results["data"].append({"type": "HTTP_HEADERS", "data": headers})
                      
                      # Detect technologies from headers
                      techs = []
                      if 'server' in headers.get('Server', '').lower():
                          techs.append(headers.get('Server'))
                      if 'x-powered-by' in [h.lower() for h in headers.keys()]:
                          techs.append(headers.get('X-Powered-By', ''))
                      if techs:
                          for t in techs:
                              results["data"].append({"type": "WEBSERVER_TECHNOLOGY", "data": t})
              except Exception as e:
                  results["data"].append({"type": "ERROR", "data": str(e)})
              
              print(json.dumps(results, indent=2))
              
          except Exception as e:
              print(json.dumps({"error": str(e), "target": "${{ matrix.competitor.domain }}"}))
          finally:
              if os.path.exists(db_path):
                  os.remove(db_path)
          EOF
          
          echo "scan_id=$SCAN_ID" >> $GITHUB_OUTPUT
          echo "Scan completed for ${{ matrix.competitor.domain }}"
          cat /tmp/scan_results_${{ matrix.competitor.name }}.json

      - name: Process Results
        id: process
        run: |
          cd /tmp
          
          # Create processed results JSON
          python3 << 'EOF'
          import json
          import os
          from datetime import datetime
          
          competitor = "${{ matrix.competitor.name }}"
          domain = "${{ matrix.competitor.domain }}"
          category = "${{ matrix.competitor.category }}"
          
          try:
              with open(f'scan_results_{competitor}.json', 'r') as f:
                  raw_results = json.load(f)
          except:
              raw_results = {"data": []}
          
          # Extract key intelligence
          intel = {
              "competitor_name": competitor,
              "domain": domain,
              "category": category,
              "scan_date": datetime.utcnow().isoformat(),
              "scan_type": "${{ inputs.scan_type || 'passive' }}",
              "technologies": [],
              "subdomains": [],
              "emails": [],
              "ip_addresses": [],
              "open_ports": [],
              "ssl_info": {},
              "social_profiles": [],
              "vulnerabilities": [],
              "api_endpoints": [],
              "raw_count": len(raw_results.get("data", []))
          }
          
          # Process results by type
          data_items = raw_results.get("data", [])
          if isinstance(data_items, list):
              for item in data_items:
                  item_type = item.get('type', '')
                  data = item.get('data', '')
                  
                  if 'WEBSERVER_TECHNOLOGY' in item_type:
                      if data and data not in intel['technologies']:
                          intel['technologies'].append(str(data))
                  elif 'INTERNET_NAME' in item_type or 'SUBDOMAIN' in item_type:
                      if data and data not in intel['subdomains']:
                          intel['subdomains'].append(str(data))
                  elif 'EMAILADDR' in item_type:
                      if data and data not in intel['emails']:
                          intel['emails'].append(str(data))
                  elif 'IP_ADDRESS' in item_type:
                      if data and data not in intel['ip_addresses']:
                          intel['ip_addresses'].append(str(data))
                  elif 'TCP_PORT_OPEN' in item_type:
                      if data and data not in intel['open_ports']:
                          intel['open_ports'].append(str(data))
                  elif 'HTTP_HEADERS' in item_type:
                      intel['ssl_info'] = data if isinstance(data, dict) else {}
          
          # Deduplicate and limit
          for key in ['technologies', 'subdomains', 'emails', 'ip_addresses', 'open_ports']:
              intel[key] = list(set(intel[key]))[:50]
          
          with open(f'processed_{competitor}.json', 'w') as f:
              json.dump(intel, f, indent=2)
          
          print(f"Processed {intel['raw_count']} raw results")
          print(f"Technologies: {len(intel['technologies'])}")
          print(f"IP Addresses: {len(intel['ip_addresses'])}")
          EOF

      - name: Upload to Supabase
        if: env.SUPABASE_URL != ''
        run: |
          cd /tmp
          
          curl -X POST "${{ secrets.SUPABASE_URL }}/rest/v1/competitor_intelligence" \
            -H "apikey: ${{ secrets.SUPABASE_SERVICE_KEY }}" \
            -H "Authorization: Bearer ${{ secrets.SUPABASE_SERVICE_KEY }}" \
            -H "Content-Type: application/json" \
            -H "Prefer: return=minimal" \
            -d @processed_${{ matrix.competitor.name }}.json

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: scan-results-${{ matrix.competitor.name }}
          path: |
            /tmp/processed_${{ matrix.competitor.name }}.json
            /tmp/scan_results_${{ matrix.competitor.name }}.json
          retention-days: 30

  generate-report:
    needs: scan-competitors
    runs-on: ubuntu-latest
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: /tmp/all-scans

      - name: Generate Summary Report
        run: |
          python3 << 'EOF'
          import json
          import os
          from datetime import datetime
          
          report = {
              "generated_at": datetime.utcnow().isoformat(),
              "competitors": []
          }
          
          scan_dir = "/tmp/all-scans"
          for folder in os.listdir(scan_dir):
              folder_path = os.path.join(scan_dir, folder)
              if os.path.isdir(folder_path):
                  for file in os.listdir(folder_path):
                      if file.startswith("processed_"):
                          with open(os.path.join(folder_path, file)) as f:
                              report["competitors"].append(json.load(f))
          
          with open("/tmp/weekly_ci_report.json", "w") as f:
              json.dump(report, f, indent=2)
          
          print("=" * 60)
          print("WEEKLY COMPETITIVE INTELLIGENCE SUMMARY")
          print("=" * 60)
          for comp in report["competitors"]:
              print(f"\n{comp['competitor_name']} ({comp['domain']})")
              print(f"  Technologies: {len(comp.get('technologies', []))}")
              print(f"  IP Addresses: {len(comp.get('ip_addresses', []))}")
              print(f"  Raw Results: {comp.get('raw_count', 0)}")
          print("=" * 60)
          EOF

      - name: Upload Weekly Report
        uses: actions/upload-artifact@v4
        with:
          name: weekly-ci-report
          path: /tmp/weekly_ci_report.json
          retention-days: 90
